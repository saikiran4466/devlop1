{"dataflow":{"dfKey":"ead29f5d-1412-4bfa-a790-01bb0a86fff2","name":"Dataflow_3669","tags":null,"description":null,"definition":"{\"name\":\"Dataflow_3669\",\"version\":0,\"livyServerId\":0,\"engineVariableName\":\"\",\"components\":[{\"udfNames\":[],\"componentId\":0,\"componentName\":\"startComponent\",\"tableName\":\"\",\"category\":\"Start\",\"componentType\":\"UDF\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":0,\"dependencies\":[],\"className\":\"com.datagaps.dataflow.models.UDFComponent\",\"executionOption\":\"\",\"excludeNotification\":\"N\"},{\"code\":\"import org.apache.spark.sql.{SparkSession, DataFrame}\\r\\nimport org.apache.spark.sql.functions._\\r\\nval employeeData: List[(Int, String, Double)] \\u003d List(\\r\\n  (1, \\\"John\\\", 50000.0),\\r\\n  (2, \\\"Alice\\\", 60000.0),\\r\\n  (3, \\\"Bob\\\", 55000.0)\\r\\n)\\r\\nprintln(employeeData)\\r\\nimport spark.implicits._\\r\\n\\r\\nval employeeDF: DataFrame \\u003d employeeData.toDF(\\\"employeeId\\\", \\\"name\\\", \\\"salary\\\")\\r\\n\",\"kind\":\"spark\",\"dataSourceId\":0,\"componentId\":1,\"componentName\":\"Code 1\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"executionOption\":\"\",\"excludeNotification\":\"N\"},{\"code\":\"import org.apache.spark.sql.{SparkSession, DataFrame}\\r\\nimport org.apache.spark.sql.types._\\r\\nimport java.sql.Timestamp\\r\\nimport java.util\\r\\nimport scala.collection.JavaConverters._\\r\\n\\r\\n    val arrayList: util.ArrayList[(Timestamp, java.lang.Double)] \\u003d new util.ArrayList()\\r\\n    arrayList.add((Timestamp.valueOf(\\\"2023-08-25 12:00:00\\\"), 10.0))\\r\\n    arrayList.add((Timestamp.valueOf(\\\"2023-08-25 13:00:00\\\"), 15.0))\\r\\n    arrayList.add((Timestamp.valueOf(\\\"2023-08-25 14:00:00\\\"), 20.0))\\r\\nval schema \\u003d StructType(\\r\\n      Seq(\\r\\n        StructField(\\\"timestamp\\\", TimestampType, nullable \\u003d false),\\r\\n        StructField(\\\"value\\\", DoubleType, nullable \\u003d false)\\r\\n      )\\r\\n    )\\r\\n    val rowArray \\u003d Array(arrayList.get(0), arrayList.get(1))\\r\\n     val rownew \\u003d Row(rowArray: _*)\\r\\n     val df \\u003d spark.createDataFrame(Seq(rownew), schema)\\r\\n    // Show the DataFrame\\r\\n    df.show()\",\"kind\":\"spark\",\"dataSourceId\":0,\"componentId\":2,\"componentName\":\"Code 2\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"executionOption\":\"\",\"excludeNotification\":\"N\"}],\"isDeleteWorkSchemaTable\":\"N\"}","parameters":"[{\"name\":\"limit_rows\",\"defValueInInteractiveMode\":\"limit 10\",\"defValueInBatchMode\":\"limit 1000\"}]","version":3,"maxComponentId":2,"livyOptions":"{\"kind\":\"spark\",\"proxyUser\":\"\",\"jars\":[],\"pyFiles\":[],\"files\":[],\"driverMemory\":\"\",\"driverCores\":0,\"executorMemory\":\"\",\"executorCores\":0,\"numExecutors\":0,\"archives\":[],\"queue\":\"\",\"name\":\"\",\"conf\":{},\"heartbeatTimeoutInSecond\":0}","isDeleted":"N","userName":null,"type":"dataflow","environmentName":"","folderPath":"Dataflow","workSchemaName":null},"analysis":[],"datamodels":[],"tagDetails":[],"dataCompares":[]}
{"dataflow":{"dfKey":"8e400c62-1cc0-4330-86af-a1d1cda90fff","name":"Dataflow5240_upendar_v2_Copy","tags":null,"description":"Â southern.co client task excel plugin and email","definition":"{\"name\":\"Dataflow5240_upendar_v2_Copy\",\"description\":\"Â southern.co client task excel plugin and email\",\"version\":0,\"livyServerId\":0,\"components\":[{\"udfNames\":[],\"componentId\":0,\"componentName\":\"startComponent\",\"tableName\":\"\",\"category\":\"Start\",\"componentType\":\"UDF\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":0,\"dependencies\":[],\"className\":\"com.datagaps.dataflow.models.UDFComponent\",\"excludeNotification\":\"N\"},{\"code\":\"from py4j.java_gateway import java_import\\njava_import(spark._sc._jvm, \\\"org.apache.spark.sql.api.python.*\\\")\\n\\nimport pandas as pd\\nd \\u003d [\\n    {\\\"c1\\\":\\\"ghg\\\", \\\"c2\\\": 23, \\\"c3\\\":3.8},\\n    {\\\"c1\\\":\\\"ffg\\\", \\\"c2\\\": 65, \\\"c3\\\":5.89},\\n    {\\\"c1\\\":\\\"yty\\\", \\\"c2\\\": 33, \\\"c3\\\":6.8},\\n    {\\\"c1\\\":\\\"rtre\\\", \\\"c2\\\": 23, \\\"c3\\\":5.78},\\n    {\\\"c1\\\":\\\"ryr\\\", \\\"c2\\\": 45, \\\"c3\\\":2.70},\\n    ]\\n    \\ndf \\u003d pd.DataFrame(d)\\nprint(df)\\nprint(len(df.columns))\\nprint(len(df))\\nfsdf \\u003d spark.createDataFrame(d)\\n\\nfsdf.show(5)\\nfsdf.createOrReplaceTempView(\\\"table_1\\\")\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":1,\"componentName\":\"Code 1\",\"tableName\":\"table_1\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"from py4j.java_gateway import java_import\\njava_import(spark._sc._jvm, \\\"org.apache.spark.sql.api.python.*\\\")\\n\\nd \\u003d [\\n    {\\\"c1\\\":\\\"ghg\\\", \\\"c2_\\\": 25, \\\"c3\\\":38.9},\\n    {\\\"c1\\\":\\\"ffg\\\", \\\"c2_\\\": 45, \\\"c3\\\":5.89},\\n    {\\\"c1\\\":\\\"erdd\\\", \\\"c2_\\\": 43, \\\"c3\\\":64.8},\\n    {\\\"c1\\\":\\\"rtre\\\", \\\"c2_\\\": 22, \\\"c3\\\":5.78},\\n    {\\\"c1\\\":\\\"ewss\\\", \\\"c2_\\\": 67, \\\"c3\\\":27.7},\\n        {\\\"c1\\\":\\\"ewss\\\", \\\"c2_\\\": 67, \\\"c3\\\":27.7},\\n\\n    ]\\nfsdf \\u003d spark.createDataFrame(d)\\n\\nfsdf.show(5)\\nfsdf.createOrReplaceTempView(\\\"table_2\\\")\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":2,\"componentName\":\"Code 2\",\"tableName\":\"table_2\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"from py4j.java_gateway import java_import\\njava_import(spark._sc._jvm, \\\"org.apache.spark.sql.api.python.*\\\")\\n\\njava_object \\u003d spark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.getConnectionParams(\\\"JSON_upendar\\\",\\\"read\\\")\\n\\ndata_source_details_list \\u003d [java_object.toList().apply(i) for i in range(java_object.size())]\\n\\ndata_source_details\\u003d {i._1(): i._2() for i in data_source_details_list}\\n\\nprint(data_source_details)\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":22,\"componentName\":\"Code 22\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"executionOption\":\"\",\"excludeNotification\":\"N\"},{\"sourceDataFrame\":\"table_1\",\"targetDataFrame\":\"table_2\",\"mapping\":[{\"sourceColumn\":\"c1\",\"sourceType\":\"string\",\"targetColumn\":\"c1\",\"targetType\":\"string\",\"unique\":\"Y\",\"sourceDataFormat\":\"\",\"targetDataFormat\":\"\",\"sourceTypeChange\":\"N\",\"targetTypeChange\":\"N\"},{\"sourceColumn\":\"c2\",\"sourceType\":\"long\",\"targetColumn\":\"c2_\",\"targetType\":\"long\",\"unique\":\"N\",\"sourceDataFormat\":\"\",\"targetDataFormat\":\"\",\"sourceTypeChange\":\"N\",\"targetTypeChange\":\"N\",\"upperThreshold\":0.0,\"lowerThreshold\":0.0,\"hasThreshold\":\"N\",\"thresholdUnit\":\"\"},{\"sourceColumn\":\"c3\",\"sourceType\":\"double\",\"targetColumn\":\"c3\",\"targetType\":\"double\",\"unique\":\"N\",\"sourceDataFormat\":\"\",\"targetDataFormat\":\"\",\"sourceTypeChange\":\"N\",\"targetTypeChange\":\"N\",\"upperThreshold\":0.0,\"lowerThreshold\":0.0,\"hasThreshold\":\"N\",\"thresholdUnit\":\"\"}],\"onlyInA\":\"Y\",\"onlyInB\":\"Y\",\"difference\":\"Y\",\"enableTrim\":\"N\",\"replaceNull\":\"N\",\"autoDataTypeConversion\":\"N\",\"columnDifferencesCount\":\"N\",\"ignoreCase\":\"N\",\"subDataFrames\":[{\"subDataFrameName\":\"_Source_Duplicate\",\"type\":\"Duplicates In A\"},{\"subDataFrameName\":\"_Target_Duplicate\",\"type\":\"Duplicates In B\"},{\"subDataFrameName\":\"_Matched\",\"type\":\"Matched\"},{\"subDataFrameName\":\"_OnlySource\",\"type\":\"Only In A\"},{\"subDataFrameName\":\"_OnlyTarget\",\"type\":\"Only In B\"},{\"subDataFrameName\":\"_Difference\",\"type\":\"Difference\"}],\"componentId\":3,\"componentName\":\"Data Compare 3\",\"tableName\":\"Data_Compare_3\",\"category\":\"Data Quality\",\"componentType\":\"Data Compare\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[2,1],\"options\":{},\"className\":\"com.datagaps.dataflow.models.DataCompareComponent\",\"isCheckpointEnabled\":\"N\",\"executionOption\":\"allparentpassorfail\",\"excludeNotification\":\"N\"},{\"pluginId\":\"244a065c-88bd-4437-8ff9-f25970876ace\",\"pluginName\":\"Export data compare results to shared folder\",\"pluginOptions\":{\"parameters\":[{\"parameterId\":\"eae5284a-dfce-4c2b-9e1f-2e1b67087ace\",\"fieldName\":\"work_book\",\"displayName\":\"Enter excel file name\",\"value\":\"result123\",\"dataType\":\"String\"},{\"parameterId\":\"1c1f07e3-ebfc-4045-88ec-e8dc7f202ace\",\"fieldName\":\"component_name\",\"displayName\":\"Enter component name\",\"value\":\"Data Compare 3\",\"dataType\":\"String\"},{\"parameterId\":\"996ef056-70d1-424a-91b5-335884b3dace\",\"fieldName\":\"source\",\"displayName\":\"Enter alias name for source\",\"value\":\"source_tab\",\"dataType\":\"String\"},{\"parameterId\":\"dfbd6427-5838-4a70-8fa8-c969735b9ace\",\"fieldName\":\"target\",\"displayName\":\"Enter alias name for target\",\"value\":\"target_tab\",\"dataType\":\"String\"}],\"inputDatasets\":[],\"outputDatasets\":[],\"dataSources\":[{\"paramId\":\"1cbecd7e-e335-4689-8f2b-668ae2c9887c\",\"fieldName\":\"data_source\",\"displayName\":\"Select Shared Folder Data Source\",\"value\":\"2033\"}]},\"componentId\":15,\"componentName\":\"Plugin 15\",\"tableName\":\"Plugin_15\",\"category\":\"Processor\",\"componentType\":\"Plugin\",\"rank\":0,\"displayRows\":0,\"dependencies\":[3],\"options\":{},\"className\":\"com.datagaps.dataflow.models.PluginComponent\",\"executionOption\":\"allparentpassorfail\",\"excludeNotification\":\"N\"},{\"code\":\"from py4j.java_gateway import java_import\\r\\njava_import(spark._sc._jvm, \\\"org.apache.spark.sql.api.python.*\\\")\\r\\n\\r\\nimport json\\r\\nimport math\\r\\nimport os\\r\\nimport time\\r\\nfrom datetime import datetime\\r\\n\\r\\nimport pandas as pd\\r\\nimport smbclient\\r\\n\\r\\nt1\\u003dtime.time()\\r\\n\\r\\njava_object \\u003d spark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.getConnectionParams(\\\"shared_folder_upendar\\\",\\\"read\\\")\\r\\n\\r\\ndata_source_details_list \\u003d [java_object.toList().apply(i) for i in range(java_object.size())]\\r\\ndata_source_details\\u003d {i._1(): i._2() for i in data_source_details_list}\\r\\n\\r\\nif data_source_details.get(\\\"impersonate\\\")\\u003d\\u003d\\\"true\\\":\\r\\n\\tusername \\u003d data_source_details[\\\"userName\\\"]\\r\\n\\tpassword \\u003d spark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.getDecryptedPassword(data_source_details[\\\"password\\\"])\\r\\n\\tsmbclient.ClientConfig(username\\u003dusername, password\\u003dpassword)\\r\\nelse:\\r\\n\\tsmbclient.ClientConfig()\\r\\n\\r\\ncomponent_name \\u003d \\\"Data Compare 3\\\"\\r\\nfile_location \\u003d data_source_details[\\\"path\\\"].split(\\\"smb:\\\")[-1]\\r\\nfile_name \\u003d \\\"result123\\\"+\\\".xlsx\\\"\\r\\nsource \\u003d \\\"source_tab\\\"\\r\\ntarget \\u003d \\\"target_tab\\\"\\r\\n\\r\\n\\r\\ndate_folder \\u003d datetime.now().strftime(\\\"%Y/%b/%d\\\")\\r\\nfinal_folder \\u003d os.path.join(file_location, date_folder)\\r\\n\\r\\nsmbclient.makedirs(final_folder, exist_ok\\u003dTrue)\\r\\nfile_full_path \\u003d os.path.join(final_folder, file_name)\\r\\ndef highlight_cells(val, min_v, max_v):\\r\\n\\tcolor \\u003d \\\"black\\\"\\r\\n\\tif \\\"V : \\\" in str(val):\\r\\n\\t\\tthreshold \\u003d float(val.split(\\\"V : \\\")[-1])\\r\\n\\t\\tif max_v \\u003e threshold \\u003e min_v:\\r\\n\\t\\t\\tcolor \\u003d \\u0027green\\u0027\\r\\n\\t\\telse:\\r\\n\\t\\t\\tcolor \\u003d \\\"red\\\"\\r\\n\\r\\n\\treturn \\u0027color: {}\\u0027.format(color)\\r\\n\\r\\n\\r\\nscala_output \\u003d json.loads(spark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.getDataCompareDownloadDetails(24558, component_name))\\r\\n\\r\\nscala_output[\\\"column_validations\\\"] \\u003d scala_output[\\\"column_validations\\\"] if scala_output.get(\\\"column_validations\\\") else {}\\r\\ncomponent_dataset_name \\u003d scala_output[\\\"dataset_name\\\"]\\r\\n\\r\\ncreated_date \\u003d datetime.strptime(scala_output[\\\"run_date\\\"], \\\"%Y-%m-%d %H:%M:%S.%f\\\").strftime(\\\"%m/%d/%Y %H:%M:%S %p\\\")\\r\\ndataset_name_to_sheet_name \\u003d {\\r\\n\\tf\\\"{component_dataset_name}_Matched\\\": \\\"Matched\\\",\\r\\n\\tf\\\"{component_dataset_name}_Source_Duplicate\\\": f\\\"Duplicates in Source-{source}\\\"[:31],\\r\\n\\tf\\\"{component_dataset_name}_Target_Duplicate\\\": f\\\"Duplicates in Target-{target}\\\"[:31],\\r\\n\\tf\\\"{component_dataset_name}_Difference\\\": \\\"Differences\\\",\\r\\n\\tf\\\"{component_dataset_name}_OnlySource\\\": f\\\"Only in Source-{source}\\\"[:31],\\r\\n\\tf\\\"{component_dataset_name}_OnlyTarget\\\": f\\\"Only in Target-{target}\\\"[:31]\\r\\n}\\r\\n\\r\\nthird_line_of_sheet \\u003d {\\r\\n\\tf\\\"{component_dataset_name}_Matched\\\": f\\\"Matched Between (S) {source} and (T) {target}\\\",\\r\\n\\tf\\\"{component_dataset_name}_Source_Duplicate\\\": f\\\"Duplicates in Source-{source}\\\",\\r\\n\\tf\\\"{component_dataset_name}_Target_Duplicate\\\": f\\\"Duplicates in Target-{target}\\\",\\r\\n\\tf\\\"{component_dataset_name}_Difference\\\": f\\\"Differences Between (S) {source} and (T) {target}\\\",\\r\\n\\tf\\\"{component_dataset_name}_OnlySource\\\": f\\\"Data Only in Source {source}\\\",\\r\\n\\tf\\\"{component_dataset_name}_OnlyTarget\\\": f\\\"Data Only in Target {target}\\\"\\r\\n}\\r\\n\\r\\nstatus_mapping \\u003d {\\\"Ok\\\": \\\"Success\\\", \\\"Failed\\\": \\\"Fail\\\"}\\r\\n\\r\\nname_mapping \\u003d {\\r\\n\\t\\\"only_source\\\": f\\\"Data Only in Source: {source}\\\",\\r\\n\\t\\\"source_duplicates\\\": f\\\"Duplicates in Source: {source}\\\",\\r\\n\\t\\\"only_target\\\": f\\\"Data Only in Target: {target}\\\",\\r\\n\\t\\\"target_duplicates\\\": f\\\"Duplicates in Target: {target}\\\",\\r\\n}\\r\\n\\r\\nno_change_dataset_names \\u003d [f\\\"{component_dataset_name}_OnlySource\\\",\\r\\n\\t\\t\\t\\t\\t\\t   f\\\"{component_dataset_name}_OnlyTarget\\\", f\\\"{component_dataset_name}_Source_Duplicate\\\",\\r\\n\\t\\t\\t\\t\\t\\t   f\\\"{component_dataset_name}_Target_Duplicate\\\"]\\r\\nmatched_dataset \\u003d f\\\"{component_dataset_name}_Matched\\\"\\r\\ndifference_dataset \\u003d f\\\"{component_dataset_name}_Difference\\\"\\r\\n\\r\\n\\r\\n# with open(file_full_path, \\\"wb\\\") as f:\\r\\nwith smbclient.open_file(file_full_path, \\\"wb\\\") as f:\\r\\n\\twriter \\u003d pd.ExcelWriter(f, engine\\u003d\\\"xlsxwriter\\\")\\r\\n\\tworkbook \\u003d writer.book\\r\\n\\r\\n\\tblue_background_bold_white \\u003d workbook.add_format({\\u0027bg_color\\u0027: \\u0027#0066CC\\u0027, \\u0027bold\\u0027: True, \\u0027font_color\\u0027: \\\"white\\\"})\\r\\n\\tyellow_background_bold \\u003d workbook.add_format({\\u0027bg_color\\u0027: \\u0027yellow\\u0027, \\u0027bold\\u0027: True})\\r\\n\\tred_font_color \\u003d workbook.add_format({\\u0027font_color\\u0027: \\\"red\\\"})\\r\\n\\tred_font_color_bold \\u003d workbook.add_format({\\u0027font_color\\u0027: \\\"red\\\",\\u0027bold\\u0027: True})\\r\\n\\tgreen_font_color \\u003d workbook.add_format({\\u0027font_color\\u0027: \\\"green\\\"})\\r\\n\\tbold \\u003d workbook.add_format({\\u0027bold\\u0027: True})\\r\\n\\talign_center_bold \\u003d workbook.add_format({\\u0027align\\u0027: \\u0027center\\u0027, \\u0027bold\\u0027: True})\\r\\n\\talign_center \\u003d workbook.add_format({\\u0027align\\u0027: \\u0027center\\u0027})\\r\\n\\ttext_wrap \\u003d workbook.add_format({\\u0027align\\u0027: \\u0027left\\u0027, \\u0027valign\\u0027:\\u0027top\\u0027})\\r\\n\\ttext_wrap.set_text_wrap()\\r\\n\\tpercent_format \\u003d workbook.add_format()\\r\\n\\tpercent_format.set_num_format(\\\"0.00%\\\")\\r\\n\\r\\n\\t# summary sheet\\r\\n\\tworksheet \\u003d workbook.add_worksheet(name\\u003d\\\"Summary\\\")\\r\\n\\tsecond_line \\u003d f\\\"{source} (S) / {target} (T)\\\"\\r\\n\\tworksheet.merge_range(0, 0, 0, 3, scala_output[\\u0027dataflow_name\\u0027], align_center_bold)\\r\\n\\tworksheet.merge_range(1, 0, 1, 3, second_line, align_center_bold)\\r\\n\\tworksheet.merge_range(2, 0, 2, 3, f\\\"Summary Totals - {created_date}\\\", align_center)\\r\\n\\r\\n\\tworksheet.write(5, 0, f\\\"Source: {source} Count : {scala_output[\\u0027source_dataset\\u0027][\\u0027count\\u0027]}\\\", bold)\\r\\n\\tworksheet.write(6, 0, f\\\"Target: {target} Count : {scala_output[\\u0027target_dataset\\u0027][\\u0027count\\u0027]}\\\", bold)\\r\\n\\tif scala_output[\\u0027difference_count\\u0027]:\\r\\n\\t\\tworksheet.write(7, 0,\\r\\n\\t\\t\\t\\t\\t\\tf\\\"Data difference in both Source: {source} and Target: {target} : {scala_output[\\u0027difference_count\\u0027]}\\\",\\r\\n\\t\\t\\t\\t\\t\\tred_font_color_bold)\\r\\n\\telse:\\r\\n\\t\\tworksheet.write(7, 0,\\r\\n\\t\\t\\t\\t\\t\\tf\\\"Data difference in both Source: {source} and Target: {target} : {scala_output[\\u0027difference_count\\u0027]}\\\",\\r\\n\\t\\t\\t\\t\\t\\tbold)\\r\\n\\tworksheet.write(8, 0, f\\\"Matched Data : {scala_output[\\u0027matched_count\\u0027]}\\\", bold)\\r\\n\\r\\n\\tfor c, i in enumerate([\\\"Name\\\", \\\"Total\\\", \\\"percentage(%)\\\", \\\"Status\\\"]):\\r\\n\\t\\tworksheet.write(9, c, i, blue_background_bold_white)\\r\\n\\r\\n\\tfor c, i in enumerate([\\\"only_source\\\", \\\"source_duplicates\\\", \\\"only_target\\\", \\\"target_duplicates\\\"]):\\r\\n\\t\\tworksheet.write(10 + c, 0, name_mapping[i])\\r\\n\\t\\tworksheet.write(10 + c, 1, scala_output[i][\\\"count\\\"])\\r\\n\\t\\tworksheet.write(10 + c, 2, scala_output[i][\\\"percent\\\"] / 100, percent_format)\\r\\n\\t\\tif scala_output[i][\\\"status\\\"] \\u003d\\u003d \\\"Failed\\\":\\r\\n\\t\\t\\tcell_font_color \\u003d red_font_color\\r\\n\\t\\telse:\\r\\n\\t\\t\\tcell_font_color \\u003d green_font_color\\r\\n\\r\\n\\t\\tworksheet.write(10 + c, 3, status_mapping[scala_output[i][\\\"status\\\"]], cell_font_color)\\r\\n\\r\\n\\tworksheet.set_column(0, 0, len(f\\\"Data difference in both Source: {source} and Target: {target}\\\"))\\r\\n\\tworksheet.set_column(1, 1, len(\\\"Total\\\"))\\r\\n\\tworksheet.set_column(2, 2, len(\\\"percentage(%)\\\"))\\r\\n\\tworksheet.set_column(3, 3, len(\\\"Status\\\"))\\r\\n\\r\\n\\t# query sheet\\r\\n\\tworksheet \\u003d workbook.add_worksheet(name\\u003d\\\"Queries\\\")\\r\\n\\tworksheet.write(0, 0, scala_output[\\u0027dataflow_name\\u0027], align_center_bold)\\r\\n\\tworksheet.write(1, 0, second_line, align_center_bold)\\r\\n\\tqueries_third_line \\u003d f\\\"Queries for {source} (S) / {target} (T)\\\"\\r\\n\\tworksheet.write(2, 0, queries_third_line, align_center)\\r\\n\\r\\n\\tworksheet.write(4, 0, f\\\"{source} Query (S)\\\", blue_background_bold_white)\\r\\n\\tworksheet.write(5, 0, scala_output[\\u0027source_dataset\\u0027][\\u0027query\\u0027], text_wrap)\\r\\n\\tworksheet.write(7, 0, f\\\"{target} Query (T)\\\", blue_background_bold_white)\\r\\n\\tworksheet.write(8, 0, scala_output[\\u0027target_dataset\\u0027][\\u0027query\\u0027], text_wrap)\\r\\n\\r\\n\\tworksheet.set_column(0, 0, max([len(_) for _ in [scala_output[\\u0027dataflow_name\\u0027], queries_third_line]]))\\r\\n\\tworksheet.set_row(5, 200)\\r\\n\\tworksheet.set_row(8, 200)\\r\\n\\tstart_header \\u003d 4\\r\\n\\tstart_data \\u003d 5\\r\\n\\r\\n\\t#  _Matched, _OnlySource, _OnlyTarget, _Source_Duplicate, _Target_Duplicate, _Difference\\r\\n\\tfor dataset_name in [matched_dataset]+no_change_dataset_names+[difference_dataset]:\\r\\n\\t\\tsheet_name \\u003d dataset_name_to_sheet_name[dataset_name]\\r\\n\\t\\ttry:\\r\\n\\t\\t\\tsdf \\u003d spark.sql(\\\"select * from {}\\\".format(dataset_name))\\r\\n\\t\\texcept:\\r\\n\\t\\t\\tworksheet \\u003d workbook.add_worksheet(name\\u003dsheet_name)\\r\\n\\t\\t\\tworksheet.write(0, 0, scala_output[\\u0027dataflow_name\\u0027], align_center_bold)\\r\\n\\t\\t\\tworksheet.write(1, 0, second_line, align_center_bold)\\r\\n\\t\\t\\tworksheet.write(2, 0, third_line_of_sheet[dataset_name], align_center)\\r\\n\\t\\t\\terror_msg \\u003d f\\\"Note: No data available for dataset {sheet_name}\\\"\\r\\n\\t\\t\\tmerged_column_width \\u003d max([len(_) for _ in [scala_output[\\u0027dataflow_name\\u0027], second_line, error_msg, third_line_of_sheet[dataset_name]]])\\r\\n\\t\\t\\tworksheet.set_row(start_header, cell_format\\u003dyellow_background_bold)\\r\\n\\t\\t\\tworksheet.set_column(0, 0, merged_column_width)\\r\\n\\t\\t\\tcontinue\\r\\n\\r\\n\\t\\tdf \\u003d sdf.toPandas()\\r\\n\\t\\tno_of_rows \\u003d len(df)\\r\\n\\t\\tno_of_columns \\u003d len(df.columns)\\r\\n\\t\\tfirst_time \\u003d True\\r\\n\\t\\tif dataset_name.endswith(\\\"_Difference\\\"):\\r\\n\\t\\t\\tfor column_name, rules in scala_output[\\u0027column_validations\\u0027].items():\\r\\n\\t\\t\\t\\tmin_v \\u003d rules[\\\"lower\\\"]\\r\\n\\t\\t\\t\\tmax_v \\u003d rules[\\\"upper\\\"]\\r\\n\\t\\t\\t\\tif first_time:\\r\\n\\t\\t\\t\\t\\tdf_style \\u003d df.style.applymap(highlight_cells, subset\\u003dpd.IndexSlice[:, [column_name]], min_v\\u003dmin_v,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t max_v\\u003dmax_v)\\r\\n\\t\\t\\t\\t\\tfirst_time \\u003d False\\r\\n\\t\\t\\t\\telse:\\r\\n\\t\\t\\t\\t\\tdf_style \\u003d df_style.applymap(highlight_cells, subset\\u003dpd.IndexSlice[:, [column_name]], min_v\\u003dmin_v,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t max_v\\u003dmax_v)\\r\\n\\r\\n\\t\\tif first_time:\\r\\n\\t\\t\\tdf.to_excel(writer, sheet_name\\u003dsheet_name, index\\u003dFalse, startrow\\u003dstart_data, header\\u003dFalse)\\r\\n\\t\\telse:\\r\\n\\t\\t\\tdf_style.to_excel(writer, sheet_name\\u003dsheet_name, index\\u003dFalse, startrow\\u003dstart_data, header\\u003dFalse)\\r\\n\\t\\tworksheet \\u003d writer.sheets[sheet_name]\\r\\n\\t\\tworksheet.merge_range(0, 0, 0, no_of_columns-1, scala_output[\\u0027dataflow_name\\u0027], align_center_bold)\\r\\n\\t\\tworksheet.merge_range(1, 0, 1, no_of_columns-1, second_line, align_center_bold)\\r\\n\\t\\tworksheet.merge_range(2, 0, 2, no_of_columns-1, third_line_of_sheet[dataset_name], align_center)\\r\\n\\t\\tmerged_column_width \\u003d max([len(_) for _ in [scala_output[\\u0027dataflow_name\\u0027], second_line, third_line_of_sheet[dataset_name]]])\\r\\n\\t\\tcolumn_widths \\u003d {}\\r\\n\\t\\tfor col_number, column_name in enumerate(df.columns.values):\\r\\n\\t\\t\\tworksheet.write(start_header, col_number, column_name)\\r\\n\\t\\t\\tif df.empty:\\r\\n\\t\\t\\t\\tcolumn_width \\u003d len(column_name)\\r\\n\\t\\t\\telse:\\r\\n\\t\\t\\t\\tcolumn_width \\u003d max(df[column_name].astype(str).map(len).max(), len(column_name))\\r\\n\\t\\t\\tcolumn_widths[col_number] \\u003d column_width\\r\\n\\t\\t\\tif dataset_name.endswith(\\\"_Matched\\\") and column_name in scala_output[\\\"column_validations\\\"].keys():\\r\\n\\t\\t\\t\\tworksheet.conditional_format(start_data, col_number, no_of_rows + start_header, col_number,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t {\\u0027type\\u0027: \\u0027text\\u0027,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\u0027criteria\\u0027: \\u0027begins with\\u0027,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\u0027value\\u0027: \\u0027A : \\u0027,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\u0027format\\u0027: green_font_color})\\r\\n\\t\\t\\telif dataset_name.endswith(\\\"_Difference\\\") and column_name not in scala_output[\\\"column_validations\\\"].keys():\\r\\n\\t\\t\\t\\tworksheet.conditional_format(start_data, col_number, no_of_rows + start_header, col_number,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t {\\u0027type\\u0027: \\u0027text\\u0027,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\u0027criteria\\u0027: \\u0027begins with\\u0027,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\u0027value\\u0027: \\u0027A : \\u0027,\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\u0027format\\u0027: red_font_color})\\r\\n\\t\\tif sum(column_widths.values()) \\u003c merged_column_width:\\r\\n\\t\\t\\tdiff \\u003d merged_column_width - sum(column_widths.values())\\r\\n\\t\\t\\tpatch \\u003d math.ceil(diff / no_of_columns)\\r\\n\\t\\t\\tcolumn_widths \\u003d {k: v + patch for k, v in column_widths.items()}\\r\\n\\t\\tfor col_number, column_width in column_widths.items():\\r\\n\\t\\t\\tworksheet.set_column(col_number, col_number, column_width)\\r\\n\\r\\n\\t\\tworksheet.set_row(start_header, cell_format\\u003dblue_background_bold_white)\\r\\n\\r\\n\\r\\n\\twriter.close()\\r\\n\\r\\nprint(f\\\"Excel File({file_full_path}) Created Successfully\\\")\\r\\n\\r\\nprint(time.time()-t1)\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":21,\"componentName\":\"Code 21\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[3],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"executionOption\":\"allparentpassorfail\",\"excludeNotification\":\"N\"},{\"pluginId\":\"c5380c06-8f61-4e32-9f97-26050aa08815\",\"pluginName\":\"Write multiple datasets into a single excel file in S3\",\"pluginOptions\":{\"parameters\":[{\"parameterId\":\"d7554b1b-2a8b-4464-ad3f-fe4201158033\",\"fieldName\":\"work_book\",\"displayName\":\"Enter Excel File Name\",\"value\":\"upendar123\",\"dataType\":\"String\"}],\"inputDatasets\":[{\"inputDatasetId\":\"5c709038-41b9-479c-9593-46e10b03c5fa\",\"fieldName\":\"target_duplicate\",\"displayName\":\"Select Target Duplicate Dataset\",\"value\":\"Data_Compare_3_Target_Duplicate\"},{\"inputDatasetId\":\"a319ad51-8c24-4ed7-a5eb-6e0e27cd215b\",\"fieldName\":\"source_duplicate\",\"displayName\":\"Select Source Duplicate Dataset\",\"value\":\"Data_Compare_3_Source_Duplicate\"},{\"inputDatasetId\":\"2228036e-4bb9-4705-abe5-75554e585671\",\"fieldName\":\"only_target\",\"displayName\":\"Select Only Target Dataset\",\"value\":\"Data_Compare_3_OnlyTarget\"},{\"inputDatasetId\":\"8cf9d90f-fba5-4625-9cae-817a8e063b66\",\"fieldName\":\"only_source\",\"displayName\":\"Select Only Source Dataset\",\"value\":\"Data_Compare_3_OnlySource\"},{\"inputDatasetId\":\"8ffd195a-d98b-468a-a70d-d406a3990759\",\"fieldName\":\"differences\",\"displayName\":\"Select Difference Dataset\",\"value\":\"Data_Compare_3_Difference\"},{\"inputDatasetId\":\"0eff0e6e-f5f0-42ec-92a2-81613a8ccfaf\",\"fieldName\":\"matched\",\"displayName\":\"Select Matched Dataset\",\"value\":\"Data_Compare_3_Matched\"}],\"outputDatasets\":[],\"dataSources\":[{\"paramId\":\"03d64e38-161a-4767-bf2a-9df4ee29e8be\",\"fieldName\":\"source_datasource\",\"displayName\":\"Select Excel Data Source\",\"value\":\"1923\"}]},\"componentId\":23,\"componentName\":\"Plugin 23\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Plugin\",\"rank\":0,\"displayRows\":0,\"dependencies\":[3],\"options\":{},\"className\":\"com.datagaps.dataflow.models.PluginComponent\",\"executionOption\":\"allparentpassorfail\",\"excludeNotification\":\"N\"},{\"pluginId\":\"cbb7e277-a5c5-4d7f-a51e-b08df4984546\",\"pluginName\":\"Write multiple datasets into a single excel file in ADLS\",\"pluginOptions\":{\"parameters\":[{\"parameterId\":\"d7554b1b-2a8b-4464-ad3f-fe4201158033\",\"fieldName\":\"work_book\",\"displayName\":\"Enter Excel File Name\",\"value\":\"upendar123\",\"dataType\":\"String\"}],\"inputDatasets\":[{\"inputDatasetId\":\"5c709038-41b9-479c-9593-46e10b03c5fa\",\"fieldName\":\"target_duplicate\",\"displayName\":\"Select Target Duplicate Dataset\",\"value\":\"Data_Compare_3_Target_Duplicate\"},{\"inputDatasetId\":\"a319ad51-8c24-4ed7-a5eb-6e0e27cd215b\",\"fieldName\":\"source_duplicate\",\"displayName\":\"Select Source Duplicate Dataset\",\"value\":\"Data_Compare_3_Source_Duplicate\"},{\"inputDatasetId\":\"2228036e-4bb9-4705-abe5-75554e585671\",\"fieldName\":\"only_target\",\"displayName\":\"Select Only Target Dataset\",\"value\":\"Data_Compare_3_OnlyTarget\"},{\"inputDatasetId\":\"8cf9d90f-fba5-4625-9cae-817a8e063b66\",\"fieldName\":\"only_source\",\"displayName\":\"Select Only Source Dataset\",\"value\":\"Data_Compare_3_OnlySource\"},{\"inputDatasetId\":\"8ffd195a-d98b-468a-a70d-d406a3990759\",\"fieldName\":\"differences\",\"displayName\":\"Select Difference Dataset\",\"value\":\"Data_Compare_3_Difference\"},{\"inputDatasetId\":\"0eff0e6e-f5f0-42ec-92a2-81613a8ccfaf\",\"fieldName\":\"matched\",\"displayName\":\"Select Matched Dataset\",\"value\":\"Data_Compare_3_Matched\"}],\"outputDatasets\":[],\"dataSources\":[{\"paramId\":\"03d64e38-161a-4767-bf2a-9df4ee29e8be\",\"fieldName\":\"source_datasource\",\"displayName\":\"Select Excel Data Source\",\"value\":\"1917\"}]},\"componentId\":24,\"componentName\":\"Plugin 24\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Plugin\",\"rank\":0,\"displayRows\":0,\"dependencies\":[3],\"options\":{},\"className\":\"com.datagaps.dataflow.models.PluginComponent\",\"executionOption\":\"allparentpassorfail\",\"excludeNotification\":\"N\"}],\"isDeleteWorkSchemaTable\":\"N\"}","parameters":"[{\"name\":\"limit_rows\",\"defValueInInteractiveMode\":\"limit 10\",\"defValueInBatchMode\":\"limit 1000\"}]","version":3,"maxComponentId":24,"livyOptions":"{\"kind\":\"spark\",\"proxyUser\":\"\",\"jars\":[],\"pyFiles\":[],\"files\":[],\"driverMemory\":\"\",\"driverCores\":0,\"executorMemory\":\"\",\"executorCores\":0,\"numExecutors\":0,\"archives\":[],\"queue\":\"\",\"name\":\"\",\"conf\":{},\"heartbeatTimeoutInSecond\":0}","isDeleted":"N","userName":null,"type":"dataflow","environmentName":null,"folderPath":"Dataflow/CLI_TEST","workSchemaName":null},"analysis":[],"datamodels":[],"tagDetails":[],"dataCompares":[]}
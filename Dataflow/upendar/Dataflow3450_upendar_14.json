{"dataflow":{"dfKey":"56022087-9e17-4bf2-9bbf-a02e02b2aeba","name":"Dataflow3450_upendar_14","tags":null,"description":"ICF requirements","definition":"{\"name\":\"Dataflow3450_upendar_14\",\"description\":\"ICF requirements\",\"version\":0,\"livyServerId\":0,\"components\":[{\"udfNames\":[],\"componentId\":0,\"componentName\":\"startComponent\",\"tableName\":\"\",\"category\":\"Start\",\"componentType\":\"UDF\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":0,\"dependencies\":[],\"className\":\"com.datagaps.dataflow.models.UDFComponent\",\"excludeNotification\":\"N\"},{\"code\":\"print(\\\"hai\\\")\\nfrom datagaps_utilities import send_email\\nsend_email(session_object\\u003dspark,to\\u003d\\\"upendar.pinni@datagaps.com\\\",subject\\u003d\\\"mail test\\\",content\\u003d\\\"testing mail\\\", content_type\\u003d\\\"Plain\\\")\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":1,\"componentName\":\"Code 1\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"import pprint\\r\\nimport pandas as pd\\r\\n\\r\\n# output dataset names\\r\\nsource_meta_data_name \\u003d \\\"source_meta_data\\\"\\r\\nexpected_meta_data_name \\u003d \\\"expected_meta_data\\\"\\r\\n\\r\\ncolumn_length \\u003d 12\\r\\n\\r\\n# input file paths\\r\\nsource_file_path \\u003d \\\"/home/datagaps/upendar/excel_files/sample2.xls\\\"\\r\\nexpected_file_path \\u003d \\\"/home/datagaps/upendar/csv_files/expected_csv.csv\\\"\\r\\n\\r\\ndf \\u003d pd.read_csv(expected_file_path)\\r\\nexpected_meta_data \\u003d spark.createDataFrame(df)\\r\\nexpected_meta_data.createOrReplaceTempView(expected_meta_data_name)\\r\\n\\r\\n\\r\\ndf_dict \\u003d pd.read_excel(source_file_path, sheet_name\\u003dNone)\\r\\n\\r\\nfinal_res \\u003d {}\\r\\nfinal_list \\u003d []\\r\\nfor sheet_name, dataframe in df_dict.items():\\r\\n    for col, col_type in dataframe.dtypes.items():\\r\\n        final_list.append({\\\"sheet_name\\\": sheet_name, \\\"column_name\\\": col, \\\"column_type\\\": col_type.name})\\r\\n\\r\\nfor sheet_name, dataframe in df_dict.items():\\r\\n    columns \\u003d dataframe.columns.to_list()\\r\\n    error \\u003d None\\r\\n    if columns:\\r\\n        if len(set(columns)) \\u003d\\u003d len(columns):\\r\\n            for col in columns:\\r\\n                if len(col) \\u003d\\u003d column_length:\\r\\n                    status \\u003d \\\"success\\\"\\r\\n                else:\\r\\n                    status \\u003d \\\"fail\\\"\\r\\n                    error \\u003d f\\\"column length of {col} is not equal to {column_length}\\\"\\r\\n                    break\\r\\n\\r\\n                if len(col) \\u003d\\u003d len(col.strip()):\\r\\n                    status \\u003d \\\"success\\\"\\r\\n                else:\\r\\n                    status \\u003d \\\"fail\\\"\\r\\n                    error \\u003d f\\\"{col} column name has spaces at edge\\\"\\r\\n                    break\\r\\n        else:\\r\\n            status \\u003d \\\"fail\\\"\\r\\n            error \\u003d \\\"column names have duplicates\\\"\\r\\n    else:\\r\\n        status \\u003d \\\"fail\\\"\\r\\n        error \\u003d f\\\"no columns in sheet {sheet_name}\\\"\\r\\n    if status:\\r\\n        final_res[sheet_name] \\u003d {\\\"columns\\\": columns, \\\"error\\\": error, \\\"status\\\": status}\\r\\nprint(\\\"\\\\n\\\\n\\\\n\\\")\\r\\n\\r\\npprint.pprint(final_res)\\r\\n\\r\\nsource_meta_data \\u003d spark.createDataFrame(final_list)\\r\\n\\r\\nsource_meta_data.createOrReplaceTempView(source_meta_data_name)\\r\\nprint(\\\"\\\\n\\\\n\\\\n\\\")\\r\\n\\r\\n\\r\\nprint(source_meta_data_name)\\r\\nsource_meta_data.show()\\r\\nprint(expected_meta_data_name)\\r\\nexpected_meta_data.show()\\r\\n\\r\\nprint(\\\"\\\\n\\\\n\\\\n\\\")\\r\\n\\r\\n\\r\\nfile_error \\u003d None\\r\\nif len(final_res.keys()) \\u003e len(set(df[\\\"sheet_name\\\"].to_list())):\\r\\n    file_error \\u003d \\\"user added more sheet tabs\\\"\\r\\nelif len(final_res.keys()) \\u003c len(set(df[\\\"sheet_name\\\"].to_list())):\\r\\n    file_error \\u003d \\\"user removed sheet tabs\\\"\\r\\nelse:\\r\\n    if set(final_res.keys()) !\\u003d set(df[\\\"sheet_name\\\"].to_list()):\\r\\n        file_error \\u003d \\\"user amended sheet tabs\\\"\\r\\nsheet_wise_errors \\u003d {}\\r\\nfor sheet_name in final_res.keys():\\r\\n    if sheet_name in set(df[\\\"sheet_name\\\"].to_list()):\\r\\n        errors \\u003d []\\r\\n        for col in final_res[sheet_name][\\\"columns\\\"]:\\r\\n            if col not in df.loc[(df.sheet_name \\u003d\\u003d sheet_name)][\\\"column_name\\\"].to_list():\\r\\n                errors.append(f\\\"column {col} modified or removed\\\")\\r\\n        sheet_wise_errors[sheet_name] \\u003d errors\\r\\n\\r\\n\\r\\npprint.pprint({\\\"file_error\\\": file_error, \\\"sheet_wise_errors\\\": sheet_wise_errors})\\r\\n\\r\\nprint(\\\"\\\\n\\\\n\\\\n\\\")\\r\\n\\r\\nfor sheet_name, dataframe in df_dict.items():\\r\\n    # print(dataframe)\\r\\n    print(dataframe.loc[dataframe.Creator \\u003d\\u003d \\\"John Doe\\\"])\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":2,\"componentName\":\"Code 2\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"import pprint\\r\\nimport pandas as pd\\r\\n\\r\\n# output dataset names\\r\\nsource_meta_data_name \\u003d \\\"input_excel\\\"\\r\\n\\r\\ncolumn_length \\u003d 12\\r\\n\\r\\n# input file paths\\r\\nsource_file_path \\u003d \\\"/home/datagaps/upendar/excel_files/sample2.xls\\\"\\r\\n\\r\\n\\r\\n\\r\\n\\r\\ndf_dict \\u003d pd.read_excel(source_file_path, sheet_name\\u003dNone)\\r\\n\\r\\nfinal_res \\u003d {}\\r\\nfinal_list \\u003d []\\r\\nc\\u003d1\\r\\nfor sheet_name, dataframe in df_dict.items():\\r\\n    for col, col_type in dataframe.dtypes.items():\\r\\n        final_list.append({\\\"id\\\":c, \\\"sheet_name\\\": sheet_name, \\\"column_name\\\": col, \\\"column_type\\\": col_type.name})\\r\\n        c+\\u003d1\\r\\n\\r\\nfor sheet_name, dataframe in df_dict.items():\\r\\n    columns \\u003d dataframe.columns.to_list()\\r\\n    error \\u003d None\\r\\n    if columns:\\r\\n        if len(set(columns)) \\u003d\\u003d len(columns):\\r\\n            for col in columns:\\r\\n                if len(col) \\u003d\\u003d column_length:\\r\\n                    status \\u003d \\\"success\\\"\\r\\n                else:\\r\\n                    status \\u003d \\\"fail\\\"\\r\\n                    error \\u003d f\\\"column length of {col} is not equal to {column_length}\\\"\\r\\n                    break\\r\\n\\r\\n                if len(col) \\u003d\\u003d len(col.strip()):\\r\\n                    status \\u003d \\\"success\\\"\\r\\n                else:\\r\\n                    status \\u003d \\\"fail\\\"\\r\\n                    error \\u003d f\\\"{col} column name has spaces at edge\\\"\\r\\n                    break\\r\\n        else:\\r\\n            status \\u003d \\\"fail\\\"\\r\\n            error \\u003d \\\"column names have duplicates\\\"\\r\\n    else:\\r\\n        status \\u003d \\\"fail\\\"\\r\\n        error \\u003d f\\\"no columns in sheet {sheet_name}\\\"\\r\\n    if status:\\r\\n        final_res[sheet_name] \\u003d {\\\"columns\\\": columns, \\\"error\\\": error, \\\"status\\\": status}\\r\\nprint(\\\"\\\\n\\\\n\\\\n\\\")\\r\\n\\r\\npprint.pprint(final_res)\\r\\n\\r\\nsource_meta_data \\u003d spark.createDataFrame(final_list)\\r\\n\\r\\nsource_meta_data.createOrReplaceTempView(source_meta_data_name)\\r\\nprint(\\\"\\\\n\\\\n\\\\n\\\")\\r\\n\\r\\n\\r\\nprint(source_meta_data_name)\\r\\nsource_meta_data.show()\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":3,\"componentName\":\"input excel\",\"tableName\":\"input_excel\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"format\":\"csv\",\"enableSchema\":\"N\",\"schema\":[],\"fileMetadata\":[],\"enableTrim\":\"N\",\"componentId\":4,\"componentName\":\"expected format\",\"tableName\":\"expected_format\",\"category\":\"Source\",\"componentType\":\"File\",\"rank\":0,\"dataSourceName\":\"CSV_upendar\",\"displayRows\":50,\"dependencies\":[],\"options\":{\"delimiter\":\",\",\"header\":\"true\",\"inferSchema\":\"true\",\"path\":\"expected_csv.csv\"},\"className\":\"com.datagaps.dataflow.models.FileComponent\",\"isCheckpointEnabled\":\"N\",\"excludeNotification\":\"N\"},{\"sourceDataFrame\":\"input_excel\",\"targetDataFrame\":\"expected_format\",\"mapping\":[{\"sourceColumn\":\"column_name\",\"sourceType\":\"string\",\"targetColumn\":\"column_name\",\"targetType\":\"string\",\"unique\":\"N\",\"sourceDataFormat\":\"\",\"targetDataFormat\":\"\",\"sourceTypeChange\":\"N\",\"targetTypeChange\":\"N\",\"originalSourceType\":\"string\",\"orginalTargetType\":\"string\"},{\"sourceColumn\":\"column_type\",\"sourceType\":\"string\",\"targetColumn\":\"column_type\",\"targetType\":\"string\",\"unique\":\"N\",\"sourceDataFormat\":\"\",\"targetDataFormat\":\"\",\"sourceTypeChange\":\"N\",\"targetTypeChange\":\"N\",\"originalSourceType\":\"string\",\"orginalTargetType\":\"string\"},{\"sourceColumn\":\"id\",\"sourceType\":\"long\",\"targetColumn\":\"id\",\"targetType\":\"integer\",\"unique\":\"Y\",\"sourceDataFormat\":\"\",\"targetDataFormat\":\"\",\"sourceTypeChange\":\"N\",\"targetTypeChange\":\"N\",\"originalSourceType\":\"long\",\"orginalTargetType\":\"integer\"},{\"sourceColumn\":\"sheet_name\",\"sourceType\":\"string\",\"targetColumn\":\"sheet_name\",\"targetType\":\"string\",\"unique\":\"N\",\"sourceDataFormat\":\"\",\"targetDataFormat\":\"\",\"sourceTypeChange\":\"N\",\"targetTypeChange\":\"N\",\"originalSourceType\":\"string\",\"orginalTargetType\":\"string\"}],\"onlyInA\":\"Y\",\"onlyInB\":\"Y\",\"difference\":\"Y\",\"enableTrim\":\"N\",\"replaceNull\":\"N\",\"autoDataTypeConversion\":\"N\",\"columnDifferencesCount\":\"N\",\"ignoreCase\":\"N\",\"subDataFrames\":[{\"subDataFrameName\":\"_Source_Duplicate\",\"type\":\"Duplicates In A\"},{\"subDataFrameName\":\"_Target_Duplicate\",\"type\":\"Duplicates In B\"},{\"subDataFrameName\":\"_Matched\",\"type\":\"Matched\"},{\"subDataFrameName\":\"_OnlySource\",\"type\":\"Only In A\"},{\"subDataFrameName\":\"_OnlyTarget\",\"type\":\"Only In B\"},{\"subDataFrameName\":\"_Difference\",\"type\":\"Difference\"}],\"componentId\":5,\"componentName\":\"Data Compare 5\",\"tableName\":\"Data_Compare_5\",\"category\":\"Data Quality\",\"componentType\":\"Data Compare\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[4,3],\"options\":{},\"className\":\"com.datagaps.dataflow.models.DataCompareComponent\",\"isCheckpointEnabled\":\"N\",\"excludeNotification\":\"N\"},{\"code\":\"sdf \\u003d spark.sql(f\\\"select * from input_excel\\\")\\n\\ndf \\u003dsdf.toPandas()\\nprint(df)\\ndf.to_csv(\\\"/home/datagaps/upendar/csv_files/expected_csv2.csv\\\", index\\u003dFalse)\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":6,\"componentName\":\"update expected format\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[3],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"}],\"isDeleteWorkSchemaTable\":\"N\"}","parameters":"[{\"name\":\"limit_rows\",\"defValueInInteractiveMode\":\"limit 10\",\"defValueInBatchMode\":\"limit 1000\"}]","version":3,"maxComponentId":6,"livyOptions":"{\"kind\":\"spark\",\"proxyUser\":\"\",\"jars\":[],\"pyFiles\":[],\"files\":[],\"driverMemory\":\"\",\"driverCores\":0,\"executorMemory\":\"\",\"executorCores\":0,\"numExecutors\":0,\"archives\":[],\"queue\":\"\",\"name\":\"\",\"conf\":{},\"heartbeatTimeoutInSecond\":0}","isDeleted":"N","userName":null,"type":"dataflow","environmentName":null,"folderPath":"Dataflow/upendar","workSchemaName":null},"analysis":[],"datamodels":[],"tagDetails":[],"dataCompares":[]}
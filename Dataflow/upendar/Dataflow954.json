{"dataflow":{"dfKey":"ee43e6ce-1fca-4e25-9313-680bedd56ad6","name":"Dataflow954","tags":null,"description":"","definition":"{\"name\":\"Dataflow954\",\"description\":\"\",\"version\":0,\"livyServerId\":0,\"engineVariableName\":\"\",\"components\":[{\"udfNames\":[],\"componentId\":0,\"componentName\":\"startComponent\",\"tableName\":\"\",\"category\":\"Start\",\"componentType\":\"UDF\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":0,\"dependencies\":[],\"className\":\"com.datagaps.dataflow.models.UDFComponent\",\"excludeNotification\":\"N\"},{\"code\":\"# # CodeUtils.saveDataset(dataset:DataFrame,datasetName:String,componentName:String,dataflowRunId:Int)\\n\\n# a\\u003dspark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.getEmailServerDetails()\\n# print(a)\\n# import json\\n# d \\u003d [\\n#     {\\\"c1\\\":\\\"ghg\\\", \\\"c2\\\": 23, \\\"c3\\\":3.8},\\n#     {\\\"c1\\\":\\\"ffg\\\", \\\"c2\\\": 65, \\\"c3\\\":5.89},\\n#     {\\\"c1\\\":\\\"yty\\\", \\\"c2\\\": 33, \\\"c3\\\":6.8},\\n#     {\\\"c1\\\":\\\"rtre\\\", \\\"c2\\\": 23, \\\"c3\\\":5.78},\\n#     {\\\"c1\\\":\\\"ryr\\\", \\\"c2\\\": 45, \\\"c3\\\":2.70},\\n#     ]\\n# ds \\u003d spark.createDataFrame(d)\\n# ds.show()\\n# ds.createOrReplaceTempView(\\\"view_name\\\")\\n# j \\u003d spark.sparkContext.parallelize(d)\\n# print(j.getNumPartitions())\\n# spark.read.json(j.map(lambda x: json.dumps(x))).show()\\n# print(spark.sql(\\\"show partitions view_name\\\").count())\\n# print(ds.RDD.getNumPartitions())\\n# spark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.saveDataset(ds,\\\"siva_test\\\",\\\"Code 1\\\", $[dataflow_run_id])\\n# print(b)\\n\\n# saveDatasetInfo(datasetName: String,schema: String,rowCount:Long,partitions:Int,dataflowRunId:Int,sampleData:String,componentName:String)\\n# datasetName:String,schema: String,rowCount:Long,partitions:Int,sampleData:String,componentName:String,dataflowRunId:Int,relations:String,dataflowId:String\\n\\nview_name \\u003d \\\"t1_c4\\\"\\nschema \\u003d \\u0027\\u0027\\u0027[{\\\"metadata\\\": {}, \\\"name\\\": \\\"a\\\", \\\"nullable\\\": true, \\\"type\\\": \\\"long\\\"}, {\\\"metadata\\\": {}, \\\"name\\\": \\\"b\\\", \\\"nullable\\\": true, \\\"type\\\": \\\"long\\\"}, {\\\"metadata\\\": {}, \\\"name\\\": \\\"dg_uid\\\", \\\"nullable\\\": true, \\\"type\\\": \\\"long\\\"}, {\\\"metadata\\\": {}, \\\"name\\\": \\\"t0_main_id\\\", \\\"nullable\\\": true, \\\"type\\\": \\\"long\\\"}]\\n\\u0027\\u0027\\u0027\\nlen_v \\u003d 1\\nno_of_partitions \\u003d 2\\nsample_output \\u003d \\u0027\\u0027\\u0027[{\\\"dg_uid\\\": 1, \\\"t0_main_id\\\": 1, \\\"a\\\": 2, \\\"b\\\": 43}, {\\\"dg_uid\\\": 2, \\\"t0_main_id\\\": 2, \\\"a\\\": 3, \\\"b\\\": 32}, {\\\"dg_uid\\\": 3, \\\"t0_main_id\\\": 3, \\\"a\\\": 32, \\\"b\\\": 34}, {\\\"dg_uid\\\": 4, \\\"t0_main_id\\\": 4, \\\"a\\\": 5, \\\"b\\\": 13}, {\\\"dg_uid\\\": 5, \\\"t0_main_id\\\": 5, \\\"a\\\": 2, \\\"b\\\": 6}]\\n\\u0027\\u0027\\u0027\\ncomponent_name \\u003d \\\"Code 6\\\"\\ndataflow_run_id \\u003d 3414\\nrelations \\u003d \\u0027\\u0027\\u0027[{\\\"parentTableName\\\": \\\"t0_main\\\", \\\"parentColumnName\\\": \\\"dg_uid\\\", \\\"childTableName\\\": \\\"t1_c4\\\", \\\"childColumnName\\\": \\\"t0_main_id\\\", \\\"relationType\\\": \\\"one-to-many\\\"}]\\u0027\\u0027\\u0027\\n\\ndataflow_id \\u003d \\\"ee43e6ce-1fca-4e25-9313-680bedd56ad6\\\"\\nspark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.saveDatasetWithRelations(\\n                view_name,\\n                schema,\\n                len_v,\\n                no_of_partitions,\\n                sample_output,\\n                component_name,\\n                dataflow_run_id,\\n                relations,\\n                dataflow_id\\n            )\\n# spark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.saveDatasetWithRelations(\\\"dataset1\\\",\\\"{}\\\",5,1,\\u0027\\u0027\\u0027[\\n#     {\\\"c1\\\":\\\"ghg\\\", \\\"c2\\\": 23, \\\"c3\\\":3.8},\\n#     {\\\"c1\\\":\\\"ffg\\\", \\\"c2\\\": 65, \\\"c3\\\":5.89},\\n#     {\\\"c1\\\":\\\"yty\\\", \\\"c2\\\": 33, \\\"c3\\\":6.8},\\n#     {\\\"c1\\\":\\\"rtre\\\", \\\"c2\\\": 23, \\\"c3\\\":5.78},\\n#     {\\\"c1\\\":\\\"ryr\\\", \\\"c2\\\": 45, \\\"c3\\\":2.70},\\n#     ]\\u0027\\u0027\\u0027,\\\"Code 1\\\",$[dataflow_run_id], \\\"{}\\\", \\\"$[dataflow_id]\\\")\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":1,\"componentName\":\"Code 1\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"import com.datagaps.core.engine.utils.CodeUtils\\n\\n\\n// val ds\\u003dspark.sqlContext.read.json(\\\"/home/datagaps/upendar/json_files/sample1.json\\\")\\n\\n\\n// CodeUtils.saveDataset(ds,\\\"siva_test\\\",\\\"Code 2\\\", $[dataflow_run_id])\\n\\nCodeUtils.deleteDatasetInfo([\\\"dataset_name1\\\", \\\"dataset_name2\\\", \\\"dataset_name3\\\"],  $[dataflow_run_id], \\\"Code 10\\\")\",\"kind\":\"spark\",\"dataSourceId\":0,\"componentId\":2,\"componentName\":\"Code 2\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"partitionOptions\":{\"partitionType\":\"\",\"name\":\"\"},\"enableTrim\":\"N\",\"easyQueryDefJson\":{\"sqlQuery\":\"\"},\"componentId\":3,\"componentName\":\"JDBC 3\",\"tableName\":\"JDBC_3\",\"category\":\"Source\",\"componentType\":\"JDBC\",\"rank\":0,\"dataSourceName\":\"PostgreSQL_s\",\"displayRows\":50,\"dependencies\":[],\"options\":{\"dbTable\":\"select id,status,current_task,pipeline_id,label,create_time,start_time,end_time,tags,priority,inputs,webhooks,outputs,parent_task_execution_id,pipeline_definition from public.job\"},\"className\":\"com.datagaps.dataflow.models.JDBCComponent\",\"isCheckpointEnabled\":\"N\",\"dataSourceLogicalName\":\"\",\"excludeNotification\":\"N\"},{\"code\":\"# # CodeUtils.saveDataset(dataset:DataFrame,datasetName:String,componentName:String,dataflowRunId:Int)\\n\\n# a\\u003dspark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.getEmailServerDetails()\\n# print(a)\\n\\nd \\u003d [\\n    {\\\"c1\\\":\\\"ghg\\\", \\\"c2\\\": 23, \\\"c3\\\":3.8},\\n    {\\\"c1\\\":\\\"ffg\\\", \\\"c2\\\": 65, \\\"c3\\\":5.89},\\n    {\\\"c1\\\":\\\"yty\\\", \\\"c2\\\": 33, \\\"c3\\\":6.8},\\n    {\\\"c1\\\":\\\"rtre\\\", \\\"c2\\\": 23, \\\"c3\\\":5.78},\\n    {\\\"c1\\\":\\\"ryr\\\", \\\"c2\\\": 45, \\\"c3\\\":2.70},\\n    ]\\nds \\u003d spark.createDataFrame(d)\\nds.show()\\nprint(ds._get_object_id)\\n# spark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.saveDataset(ds,\\\"siva_test\\\",\\\"Code 1\\\", $[dataflow_run_id])\\n# # print(b)\\n# print(dir(spark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.saveDataset))\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":5,\"componentName\":\"Code 5\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"\\nfrom datagaps_utilities import json_to_rdb\\n\\nd \\u003d [\\n    {\\\"c1\\\":\\\"ghg\\\", \\\"c2\\\": 23, \\\"c3\\\":3.8, \\\"c4\\\":{\\\"a\\\":2, \\\"b\\\":43, \\\"d\\\":{\\\"d1\\\":1, \\\"d2\\\":68}}},\\n    {\\\"c1\\\":\\\"ffg\\\", \\\"c2\\\": 65, \\\"c3\\\":5.89, \\\"c4\\\":{\\\"a\\\":3, \\\"b\\\":32, \\\"d\\\":{\\\"d1\\\":7, \\\"d2\\\":84}}},\\n    {\\\"c1\\\":\\\"yty\\\", \\\"c2\\\": 33, \\\"c3\\\":6.8, \\\"c4\\\":{\\\"a\\\":32, \\\"b\\\":34, \\\"d\\\":{\\\"d1\\\":38, \\\"d2\\\":18}}},\\n    {\\\"c1\\\":\\\"rtre\\\", \\\"c2\\\": 23, \\\"c3\\\":5.78, \\\"c4\\\":{\\\"a\\\":5, \\\"b\\\":13, \\\"d\\\":{\\\"d1\\\":3, \\\"d2\\\":8}}},\\n    {\\\"c1\\\":\\\"ryr\\\", \\\"c2\\\": 45, \\\"c3\\\":2.70, \\\"c4\\\":{\\\"a\\\":2, \\\"b\\\":6, \\\"d\\\":{\\\"d1\\\":23, \\\"d2\\\":7}}},\\n    ]\\n    \\n    \\njson_to_rdb(spark,\\\"Code 6\\\", $[dataflow_run_id],\\\"$[dataflow_id]\\\",data\\u003dd, primary_table_name\\u003d\\\"main\\\",use_short_names\\u003dTrue,parse_all_strings\\u003dFalse)\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":6,\"componentName\":\"Code 6\",\"tableName\":\"code_6\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"from datagaps_utilities.inner_functions import split_as_relational_data, prepare_relation_dict\\r\\n\\r\\nd \\u003d [\\r\\n    {\\\"c1\\\":\\\"ghg\\\", \\\"c2\\\": 23, \\\"c3\\\":3.8, \\\"c4\\\":{\\\"a\\\":2, \\\"b\\\":43, \\\"d\\\":{\\\"d1\\\":1, \\\"d2\\\":68}}},\\r\\n    {\\\"c1\\\":\\\"ffg\\\", \\\"c2\\\": 65, \\\"c3\\\":5.89, \\\"c4\\\":{\\\"a\\\":3, \\\"b\\\":32, \\\"d\\\":{\\\"d1\\\":7, \\\"d2\\\":84}}},\\r\\n    {\\\"c1\\\":\\\"yty\\\", \\\"c2\\\": 33, \\\"c3\\\":6.8, \\\"c4\\\":{\\\"a\\\":32, \\\"b\\\":34, \\\"d\\\":{\\\"d1\\\":38, \\\"d2\\\":18}}},\\r\\n    {\\\"c1\\\":\\\"rtre\\\", \\\"c2\\\": 23, \\\"c3\\\":5.78, \\\"c4\\\":{\\\"a\\\":5, \\\"b\\\":13, \\\"d\\\":{\\\"d1\\\":3, \\\"d2\\\":8}}},\\r\\n    {\\\"c1\\\":\\\"ryr\\\", \\\"c2\\\": 45, \\\"c3\\\":2.70, \\\"c4\\\":{\\\"a\\\":2, \\\"b\\\":6, \\\"d\\\":{\\\"d1\\\":23, \\\"d2\\\":7}}},\\r\\n    ]\\r\\nsession_object \\u003d spark\\r\\nprimary_table_name \\u003d \\\"main\\\"\\r\\nrelational_data \\u003d split_as_relational_data(d, primary_table_name\\u003dprimary_table_name,\\r\\n                                           use_short_names\\u003dTrue,\\r\\n                                           parse_all_strings\\u003dFalse)\\r\\n\\r\\nfinal_dict \\u003d relational_data[\\\"final_dict\\\"]\\r\\nparent_tables \\u003d relational_data[\\\"parent_tables\\\"]\\r\\nshort_names \\u003d relational_data[\\\"short_names\\\"]\\r\\n# create_spark_datasets(session_object, final_dict, short_names)\\r\\n# schema_dict \\u003d create_spark_datasets_get_schema(session_object, final_dict, short_names)\\r\\n\\r\\nrelation_dict \\u003d prepare_relation_dict(primary_table_name, parent_tables)\\r\\nprint(relation_dict)\\r\\n\\r\\ntrigger_scala_methods_for_all_datasets(relation_dict, None, final_dict, session_object, short_names, \\\"Code 6\\\",$[dataflow_run_id])\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":7,\"componentName\":\"Code 7\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"a\\u003d\\\"$[dataflow_id]\\\"\\nprint(a)\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":8,\"componentName\":\"Code 8\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"import sys\\nprint(sys.version)\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":9,\"componentName\":\"Code 9\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"spark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.deleteDatasetInfo(\\u0027[\\\"dataset_name1\\\", \\\"dataset_name2\\\", \\\"dataset_name3\\\"]\\u0027,  $[dataflow_run_id], \\\"Code 10\\\")\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":10,\"componentName\":\"Code 10\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"from datagaps_utilities.config import log_file_path, DB_HOST, DB_NAME, DB_USER, DB_PORT, DB_PASSWORD, data_source_type\\n\\nprint(log_file_path)\\n\\nwith open(log_file_path) as f:\\n    print(f.read())\\n    \\nwith open(log_file_path, \\\"w\\\") as f2:\\n    f2.write(\\\"first log\\\")\\n\\n\\nwith open(\\\"/tmp/python-utilities.log\\\", \\\"w\\\") as f2:\\n    f2.write(\\\"first log\\\")\\n    \\nwith open(\\\"/tmp/python-utilities.log\\\") as f:\\n    print(f.read())\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":11,\"componentName\":\"Code 11\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"from datagaps_utilities import api_component_to_rdb\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":13,\"componentName\":\"Code 13\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"},{\"code\":\"import com.datagaps.core.engine.utils.CodeUtils\\n\\n\\nval ds\\u003dspark.sql(\\\"select * from jdbc_3\\\")\\n\\n\\nCodeUtils.saveDataset(ds,\\\"siva_test\\\",\\\"Code 4\\\", $[dataflow_run_id])\",\"kind\":\"spark\",\"dataSourceId\":0,\"componentId\":4,\"componentName\":\"Code 4\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[3],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"excludeNotification\":\"N\"}],\"isDeleteWorkSchemaTable\":\"N\"}","parameters":"[{\"name\":\"limit_rows\",\"defValueInInteractiveMode\":\"limit 10\",\"defValueInBatchMode\":\"limit 1000\"}]","version":3,"maxComponentId":13,"livyOptions":"{\"proxyUser\":\"\",\"jars\":[],\"pyFiles\":[],\"files\":[],\"driverMemory\":\"\",\"driverCores\":0,\"executorMemory\":\"\",\"executorCores\":0,\"numExecutors\":0,\"archives\":[],\"queue\":\"\",\"name\":\"\",\"conf\":{},\"heartbeatTimeoutInSecond\":0,\"kind\":\"spark\"}","isDeleted":"N","userName":null,"type":"dataflow","environmentName":null,"folderPath":"Dataflow/upendar","workSchemaName":null},"analysis":[],"datamodels":[],"tagDetails":[],"dataCompares":[]}
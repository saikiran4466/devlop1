{"dataflow":{"dfKey":"bea10050-411e-4405-bfa4-7c1d13f08b82","name":"csv_adls_read_soft_delete","tags":null,"description":null,"definition":"{\"name\":\"csv_adls_read_soft_delete\",\"version\":0,\"livyServerId\":0,\"engineVariableName\":\"\",\"components\":[{\"udfNames\":[],\"componentId\":0,\"componentName\":\"startComponent\",\"tableName\":\"\",\"category\":\"Start\",\"componentType\":\"UDF\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":0,\"dependencies\":[],\"className\":\"com.datagaps.dataflow.models.UDFComponent\",\"executionOption\":\"allparentpassorfail\",\"excludeNotification\":\"N\"},{\"code\":\"from py4j.java_gateway import java_import\\r\\njava_import(spark._sc._jvm, \\\"org.apache.spark.sql.api.python.*\\\")\\r\\n\\r\\nimport fsspec\\r\\nimport pandas\\r\\nimport os\\r\\n#adls_csv_accfed\\r\\n#EXCEL_adls_upendar_2\\r\\nconn_map\\u003dspark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.getConnectionParams(\\\"adls_csv_accfed\\\",\\\"read\\\")\\r\\nconn\\u003d[conn_map.toList().apply(i) for i in range(conn_map.size())]\\r\\nconn_details\\u003d {i._1(): i._2() for i in conn}\\r\\nprint(conn_details)\\r\\nstorage_account_name \\u003d conn_details[\\\"storage-account\\\"]\\r\\nstorage_account_key \\u003d spark.sparkContext._jvm.com.datagaps.core.engine.utils.CodeUtils.getDecryptedPassword(conn_details[\\\"access-key\\\"])\\r\\nfile_system_name \\u003d conn_details[\\\"container\\\"]\\r\\n\\r\\nif conn_details.get(\\\"path\\\")\\u003d\\u003dNone:\\r\\n    file_full_path \\u003d os.path.join(file_system_name, \\\"API 1_API_1_food_pairing.csv\\\")\\r\\nelse:\\r\\n    file_full_path\\u003dos.path.join(conn_details[\\\"path\\\"],file_system_name, \\\"test1.csv\\\")\\r\\n    \\r\\nheader \\u003d 0 if conn_details.get(\\\"header\\\") \\u003d\\u003d \\\"true\\\" else None\\r\\n\\r\\nprint(file_full_path)\\r\\n\\r\\nurl\\u003d\\\"abfs://{}\\\".format(file_full_path)\\r\\n\\r\\nfsspec_handle \\u003d fsspec.open(url, account_name\\u003dstorage_account_name, account_key\\u003dstorage_account_key)\\r\\n\\r\\nwith fsspec_handle.open() as f:\\r\\n    df \\u003d pandas.read_csv(f)\\r\\n    df.columns\\u003ddf.columns.astype(str).str.replace(\\\"[^0-9A-Za-z_]\\\",\\\"_\\\")\\r\\nprint(df)\\r\\n\\r\\nif df.empty:\\r\\n\\temp_rdd \\u003d spark.sparkContext.emptyRDD()\\r\\n\\tcolumns \\u003d StructType([])\\r\\n\\tspark_dataframe \\u003d spark.createDataFrame(data\\u003demp_rdd,schema\\u003dcolumns)\\r\\nelse:\\r\\n\\tspark_dataframe \\u003d spark.createDataFrame(df.astype(\\u0027str\\u0027))\\r\\n\\t\\r\\n\\r\\nspark_dataframe.createOrReplaceTempView(\\u0027k\\u0027)\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":1,\"componentName\":\"Code 1\",\"tableName\":\"k\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"executionOption\":\"allparentpassorfail\",\"excludeNotification\":\"N\"},{\"pluginId\":\"825d786d-907d-4116-8967-da03edf443fd\",\"pluginName\":\"CSV file reading from ADLS\",\"pluginOptions\":{\"parameters\":[{\"parameterId\":\"5b4727eb-63d5-419d-9664-b9b47204e59c\",\"fieldName\":\"file_name\",\"displayName\":\"Enter File Name\",\"value\":\"testfile-datagaps(accentureFedral).txt\",\"dataType\":\"String\"},{\"parameterId\":\"188cde10-cd7b-4e2b-bfeb-baa91587abb3\",\"fieldName\":\"delimiter\",\"displayName\":\"Enter Delimiter\",\"value\":\"\\u0007\",\"dataType\":\"String\"}],\"inputDatasets\":[],\"outputDatasets\":[{\"outputDatasetId\":\"93d4abe6-8406-46c4-9939-d29cbef01d50\",\"fieldName\":\"output_dataset\",\"displayName\":\"Enter Dataset Name\",\"value\":\"test\"}],\"dataSources\":[{\"paramId\":\"9b38b7da-4ed7-4002-8001-e070f8f3e97e\",\"fieldName\":\"source_datasource\",\"displayName\":\"Data Source\",\"value\":\"2090\"}]},\"componentId\":3,\"componentName\":\"Plugin 3\",\"tableName\":\"Plugin_3\",\"category\":\"Processor\",\"componentType\":\"Plugin\",\"rank\":0,\"displayRows\":0,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.PluginComponent\",\"executionOption\":\"allparentpassorfail\",\"excludeNotification\":\"N\"},{\"code\":\"import pandas\\r\\nimport fsspec\\r\\n\\r\\nadls_account_name \\u003d \\u0027accenturefedaral\\u0027 #Provide exact ADLS account name\\r\\nadls_account_key \\u003d \\u00276CiJialUeUBXGidR7dEpd7yGf/qBX0843dW5o9PrSlEt+oKrvwNtcdD12OQTibygfPS+ehjGU5ik+ASt3KjObQ\\u003d\\u003d\\u0027 #Provide exact ADLS account key\\r\\n#read csv file\\r\\n#spark.conf.set(\\\"fs.azure.account.key.\\\" +adls_account_name + \\\".dfs.core1.windows.net\\\", adls_account_key)\\r\\nfile\\u003d\\\"abfs://test@accenturefedaral.dfs.core.windows.net/API 1_API_1_food_pairing.csv\\\"\\r\\n\\r\\nfsspec_handle \\u003d fsspec.open(file,account_key\\u003dadls_account_key)\\r\\n# fsspec_handle \\u003d fsspec.open(\\u0027abfs://test/API 1_API_1_food_pairing.csv\\u0027, account_name\\u003dadls_account_name, account_key\\u003dadls_account_key)\\r\\n\\r\\nwith fsspec_handle.open() as f:\\r\\n    df \\u003d pandas.read_csv(f)\\r\\n    \\r\\nprint(df)\\r\\n\\r\\n\\r\\n# df \\u003d pandas.read_csv(\\u0027abfs://test@accenturefedaral.dfs.core.windows.net/API 1_API_1_food_pairing.csv\\u0027)\\r\\n# print(df)\",\"kind\":\"pyspark\",\"dataSourceId\":0,\"componentId\":5,\"componentName\":\"Code 5\",\"tableName\":\"\",\"category\":\"Processor\",\"componentType\":\"Code\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[],\"options\":{},\"className\":\"com.datagaps.dataflow.models.CodeComponent\",\"executionOption\":\"\",\"excludeNotification\":\"N\"},{\"partitionOptions\":{\"partitionType\":\"\",\"name\":\"\"},\"easyQueryDefJson\":{\"sqlQuery\":\"\"},\"componentId\":2,\"componentName\":\"SQL 2\",\"tableName\":\"SQL_2\",\"category\":\"Processor\",\"componentType\":\"SQL\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[1],\"options\":{\"dbTable\":\"select * from k\"},\"className\":\"com.datagaps.dataflow.models.SQLComponent\",\"isCheckpointEnabled\":\"N\",\"executionOption\":\"allparentpassorfail\",\"excludeNotification\":\"N\"},{\"partitionOptions\":{\"partitionType\":\"\",\"name\":\"\"},\"easyQueryDefJson\":{\"sqlQuery\":\"\"},\"componentId\":4,\"componentName\":\"SQL 4\",\"tableName\":\"SQL_4\",\"category\":\"Processor\",\"componentType\":\"SQL\",\"rank\":0,\"dataSourceName\":\"\",\"displayRows\":50,\"dependencies\":[3],\"options\":{\"dbTable\":\"select * from test\"},\"className\":\"com.datagaps.dataflow.models.SQLComponent\",\"isCheckpointEnabled\":\"N\",\"executionOption\":\"allparentpassorfail\",\"excludeNotification\":\"N\"}],\"isDeleteWorkSchemaTable\":\"N\"}","parameters":"[{\"name\":\"limit_rows\",\"defValueInInteractiveMode\":\"limit 10\",\"defValueInBatchMode\":\"limit 1000\"}]","version":3,"maxComponentId":5,"livyOptions":"{\"proxyUser\":\"\",\"jars\":[],\"pyFiles\":[],\"files\":[],\"driverMemory\":\"\",\"driverCores\":0,\"executorMemory\":\"\",\"executorCores\":0,\"numExecutors\":0,\"archives\":[],\"queue\":\"\",\"name\":\"\",\"conf\":{},\"heartbeatTimeoutInSecond\":0,\"kind\":\"spark\"}","isDeleted":"N","userName":null,"type":"dataflow","environmentName":"","folderPath":"Dataflow","workSchemaName":null},"analysis":[],"datamodels":[],"tagDetails":[],"dataCompares":[]}